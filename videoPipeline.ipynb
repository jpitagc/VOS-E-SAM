{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import gdown\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(sys.path[0]+\"/tracker\")\n",
    "sys.path.append(sys.path[0]+\"/tracker/model\")\n",
    "from track_anything import TrackingAnything\n",
    "from track_anything import parse_augment\n",
    "import requests\n",
    "import json\n",
    "import torchvision\n",
    "import torch \n",
    "from tools.painter import mask_painter\n",
    "import psutil\n",
    "import time\n",
    "try: \n",
    "    from mmcv.cnn import ConvModule\n",
    "except:\n",
    "    os.system(\"mim install mmcv\")\n",
    "import matplotlib.pyplot as plt\n",
    "from pycocotools import mask as maskUtils\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if os.name == 'posix':\n",
    "    ovis_anotations = '../data.nosync/OVIS/annotations/'\n",
    "    ovis_images = '../data.nosync/OVIS/train_images/'\n",
    "else:\n",
    "    ovis_anotations = 'D:/HADA/data/OVIS/annotations/'\n",
    "    ovis_images = 'D:/HADA/data/OVIS/train_images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cargarDatos(ruta_ann):\n",
    "    with open(ruta_ann + 'annotations_train.json') as f:\n",
    "        annotationsTrain = json.load(f)\n",
    "\n",
    "    with open(ruta_ann + 'annotations_valid.json') as f:\n",
    "        annotationsValid = json.load(f)\n",
    "\n",
    "    with open(ruta_ann + 'annotations_test.json') as f:\n",
    "        annotationsTest = json.load(f)\n",
    "\n",
    "    clases = annotationsTrain['categories']\n",
    "    vidTrain = annotationsTrain['videos']\n",
    "    annTrain = annotationsTrain['annotations']\n",
    "    vidValid = annotationsValid['videos']\n",
    "    annValid = annotationsValid['annotations']\n",
    "    vidTest = annotationsTest['videos']\n",
    "    annTest = annotationsTest['annotations']\n",
    "\n",
    "    return clases, vidTrain, annTrain, vidValid, annValid, vidTest, annTest\n",
    "\n",
    "clases, vidTrain, annTrain, vidValid, annValid, vidTest, annTest = cargarDatos(ovis_anotations) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annToRLE(ann, frameId):\n",
    "    \"\"\"\n",
    "    Convert annotation which can be polygons, uncompressed RLE to RLE.\n",
    "    :return: binary mask (numpy 2D array)\n",
    "    \"\"\"\n",
    "    h, w = ann['height'], ann['width']\n",
    "    segm = ann['segmentations'][frameId]\n",
    "    if segm is None:\n",
    "        return None\n",
    "    if type(segm) == \"list\":\n",
    "        # polygon -- a single object might consist of multiple parts\n",
    "        # we merge all parts into one mask rle code\n",
    "        rles = maskUtils.frPyObjects(segm, h, w)\n",
    "        rle = maskUtils.merge(rles)\n",
    "    elif type(segm['counts']) == \"list\":\n",
    "        # uncompressed RLE\n",
    "        rle = maskUtils.frPyObjects(segm, h, w)\n",
    "    else:\n",
    "        # rle\n",
    "        rle = segm\n",
    "    return rle\n",
    "\n",
    "\n",
    "def annToMask(ann, frameId):\n",
    "    \"\"\"\n",
    "    Convert annotation which can be polygons, uncompressed RLE, or RLE to binary mask.\n",
    "    :return: binary mask (numpy 2D array)\n",
    "    \"\"\"\n",
    "    rle = annToRLE(ann, frameId)\n",
    "    if rle is not None:\n",
    "        m = maskUtils.decode(rle)\n",
    "        return m\n",
    "\n",
    "\n",
    "\n",
    "def combineMasks(masks, width, height):\n",
    "    # Crear una matriz vacía para la máscara combinada\n",
    "    combined = np.zeros((height, width), dtype=np.uint8)\n",
    "\n",
    "    # Combinar las máscaras en la matriz vacía\n",
    "    for mask in masks:\n",
    "        combined += mask  # Sumar la máscara a la máscara combinada\n",
    "\n",
    "    # Aplicar umbral para obtener una única máscara binaria\n",
    "    combined = np.where(combined > 0, 1, 0)\n",
    "    return combined\n",
    "\n",
    "def unifyMasks(masks, width, height):\n",
    "    # Crear una matriz vacía para la máscara combinada\n",
    "    unified = np.zeros((height, width), dtype=np.uint8)\n",
    "\n",
    "    # Combinar las máscaras en la matriz vacía\n",
    "    for mask in masks:\n",
    "        unified += mask  # Sumar la máscara a la máscara combinada\n",
    "\n",
    "    \n",
    "    return unified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_folder(path,image_files):\n",
    "    images = []\n",
    "    for file in image_files:\n",
    "        img = cv2.imread(os.path.join(path,file))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        images.append(img)\n",
    "    return images\n",
    "\n",
    "def load_all_initial_masks_from_dataset():\n",
    "    all_masks = []\n",
    "    for video in vidTrain:\n",
    "        ann = [a for a in annTrain if a['video_id'] == video['id']]\n",
    "        masks = [annToMask(a, 0) * (i + 1) for i, a in enumerate(ann) if annToMask(a, 0) is not None]\n",
    "        all_masks.append(unifyMasks(masks, video['width'], video['height']))\n",
    "    return all_masks\n",
    "\n",
    "def load_all_masks_for_video(video):\n",
    "    ann = [a for a in annTrain if a['video_id'] == video['id']]\n",
    "    all_masks  = []\n",
    "    for image_num in range(0,video['length']):\n",
    "        masks = []\n",
    "        for i, a in enumerate(ann):\n",
    "            annot = annToMask(a, image_num)\n",
    "            if annot is not None: masks.append(annot * (i + 1))\n",
    "        single_mask = unifyMasks(masks, video['width'], video['height'])\n",
    "        all_masks.append(single_mask)\n",
    "    return all_masks\n",
    "\n",
    "def pad_to_divisible_by_two(frames):\n",
    "    max_height = max(frame.shape[0] for frame in frames)\n",
    "    max_width = max(frame.shape[1] for frame in frames)\n",
    "    new_height = max_height + 1 if max_height % 2 != 0 else max_height\n",
    "    new_width = max_width + 1 if max_width % 2 != 0 else max_width\n",
    "\n",
    "    padded_frames = []\n",
    "    for frame in frames:\n",
    "        height_pad = new_height - frame.shape[0]\n",
    "        width_pad = new_width - frame.shape[1]\n",
    "        padded_frame = np.pad(frame, ((0, height_pad), (0, width_pad), (0, 0)), mode='constant')\n",
    "        padded_frames.append(padded_frame)\n",
    "\n",
    "    return padded_frames\n",
    "\n",
    "def generate_video_from_frames(frames, output_path, fps=30):\n",
    "    frames = torch.from_numpy(np.asarray(frames))\n",
    "    if not os.path.exists(os.path.dirname(output_path)):\n",
    "        os.makedirs(os.path.dirname(output_path))\n",
    "    torchvision.io.write_video(output_path, frames, fps=fps, video_codec=\"libx264\")\n",
    "    return output_path\n",
    "\n",
    "def select_smaller_set(videos, size = 100):\n",
    "    size = [(video['id'],video['height']*video['height']*len(video['file_names'])) for video in videos]\n",
    "    #size = [(video['id'],video['height']*video['height']) for video in videos]\n",
    "    sorted_list = sorted(size, key=lambda x: x[1])\n",
    "    listed = [tup[0] for tup in sorted_list[:100]]\n",
    "    filtered_list = [d for id_ in listed for d in vidTrain if d.get('id') == id_]\n",
    "    return filtered_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_iou(mask1, mask2):\n",
    "    # Ensure both masks have the same shape\n",
    "    assert mask1.shape == mask2.shape, \"Mask shapes must be the same.\"\n",
    "\n",
    "    # Calculate intersection and union for each label\n",
    "    labels = np.unique(np.concatenate((mask1, mask2)))[1:]\n",
    "    intersection = np.zeros_like(mask1, dtype=np.float32)\n",
    "    union = np.zeros_like(mask1, dtype=np.float32)\n",
    "    iou_per_label = {}\n",
    "\n",
    "    for label in labels:\n",
    "        mask1_label = mask1 == label\n",
    "        mask2_label = mask2 == label\n",
    "        c_intersection = np.logical_and(mask1_label, mask2_label)\n",
    "        c_union = np.logical_or(mask1_label, mask2_label)\n",
    "        intersection += c_intersection\n",
    "        union += c_union\n",
    "        iou_per_label[label] = np.sum(c_intersection) / np.sum(c_union)\n",
    "\n",
    "    # Calculate IoU\n",
    "    iou = np.sum(intersection) / np.sum(union)\n",
    "\n",
    "    return iou, iou_per_label\n",
    "\n",
    "def compute_f_score(true_positives, false_positives, false_negatives):\n",
    "    divider = (true_positives + false_positives)\n",
    "    precision = (true_positives / divider) if divider != 0 else 0\n",
    "\n",
    "    divider = (true_positives + false_negatives)\n",
    "    recall = (true_positives / divider) if divider != 0 else 0\n",
    "\n",
    "    divider = (precision + recall)\n",
    "    f_measure = (2 * (precision * recall) / divider) if divider != 0 else 0\n",
    "    return f_measure\n",
    "\n",
    "def compute_f_measure(mask1, mask2):\n",
    "    # Ensure both masks have the same shape\n",
    "    assert mask1.shape == mask2.shape, \"Mask shapes must be the same.\"\n",
    "\n",
    "    # Calculate F-measure for each label\n",
    "    labels = np.unique(np.concatenate((mask1, mask2)))[1:]\n",
    "    f_measure_per_label = {}\n",
    "    add_true_positives = 0\n",
    "    add_false_positives = 0\n",
    "    add_false_negatives = 0\n",
    "\n",
    "    for label in labels:\n",
    "        mask1_label = mask1 == label\n",
    "        mask2_label = mask2 == label\n",
    "\n",
    "        true_positives = np.logical_and(mask1_label, mask2_label).sum()\n",
    "        false_positives = np.logical_and(mask1_label, np.logical_not(mask2_label)).sum()\n",
    "        false_negatives = np.logical_and(np.logical_not(mask1_label), mask2_label).sum()\n",
    "\n",
    "        add_true_positives += true_positives\n",
    "        add_false_positives += false_positives\n",
    "        add_false_negatives += false_negatives\n",
    "\n",
    "        f_measure = compute_f_score(true_positives, false_positives, false_negatives)\n",
    "        f_measure_per_label[label] = f_measure\n",
    "\n",
    "    overall_f_measure = compute_f_score(add_true_positives, add_false_positives, add_false_negatives)\n",
    "    return overall_f_measure,f_measure_per_label\n",
    "\n",
    "def add_dict(list_of_dicts):\n",
    "    mean_dict = {}\n",
    "    key_counts = {}\n",
    "\n",
    "    for d in list_of_dicts:\n",
    "        for key, value in d.items():\n",
    "            mean_dict[key] = mean_dict.get(key, 0) + value\n",
    "            key_counts[key] = key_counts.get(key, 0) + 1\n",
    "\n",
    "    for key in mean_dict:\n",
    "        mean_dict[key] /= key_counts[key]\n",
    "    return mean_dict\n",
    "\n",
    "def compute_all_metrics(masks,ground_truth_masks):\n",
    "    f_measure_lst, f_measure_per_label_lst, iou_lst, iou_per_label_lst  =  [], [], [], []\n",
    "    for i,(mask_infered, mask_gt) in enumerate(zip(masks,ground_truth_masks)):\n",
    "            f_measure, f_measure_per_label = compute_f_measure(mask_infered,mask_gt)\n",
    "            iou, iou_per_label = calculate_iou(mask_infered,mask_gt)\n",
    "            #print(f'Mask {i + 1}: f_mesure {f_measure}, per label {f_measure_per_label}, iou {iou}, per label {iou_per_label}')\n",
    "            f_measure_lst.append(f_measure)\n",
    "            f_measure_per_label_lst.append(f_measure_per_label)\n",
    "            iou_lst.append(iou)\n",
    "            iou_per_label_lst.append(iou_per_label)\n",
    "    mean_f_measure = np.array(f_measure_lst).mean()\n",
    "    mean_iou = np.array(iou_lst).mean()\n",
    "    mean_f_measure_per_label  = add_dict(f_measure_per_label_lst)\n",
    "    mean_iou_per_label_label  = add_dict(iou_per_label_lst)#{key: sum(d[key] for d in iou_per_label_lst)/len(iou_per_label_lst) for key in iou_per_label_lst[0]}\n",
    "    return mean_f_measure,mean_iou, mean_f_measure_per_label, mean_iou_per_label_label\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model_on_ovis_set(name, model,path_set,videos, annotations, compute_metrics = False,save_masks = False, compute_video = False, verbose = True):\n",
    "    for video in videos:\n",
    "        # Load all images as np.array\n",
    "        if verbose: print(f'max memory allocated: {torch.cuda.max_memory_allocated()/(2**20)} MB')\n",
    "        video_folder = video[\"file_names\"][0].split(\"/\")[0]\n",
    "        if verbose: print(f'Tracking Video {video_folder} with dimensions {video[\"width\"]}x{video[\"height\"]}')\n",
    "        if verbose: print('Loading dataset images')\n",
    "        images = load_images_from_folder(path_set,video['file_names'])\n",
    "\n",
    "        # Load al poligon of first image to a usable mask\n",
    "        if verbose: print('Creating first annotated mask for VOS model')\n",
    "        ann = [a for a in annotations if a['video_id'] == video['id']]\n",
    "        masks = [(annToMask(a, 0) * (i + 1))  for i, a in enumerate(ann) if annToMask(a, 0) is not None ]\n",
    "        initial_mask = unifyMasks(masks, video['width'], video['height'])\n",
    "\n",
    "        #Compute masks for all images\n",
    "        if verbose:print('Computing all masks')\n",
    "        model.xmem.clear_memory()\n",
    "        masks, logits, painted_images = model.generator(images=images, template_mask=initial_mask)\n",
    "        model.xmem.clear_memory()  \n",
    "\n",
    "        folder_path = f'./result/{name}'\n",
    "        if compute_metrics or compute_video or save_masks: \n",
    "            if not os.path.exists(folder_path):\n",
    "                os.makedirs(folder_path)\n",
    "\n",
    "        if compute_metrics:\n",
    "            if verbose: print('Computing Metrics')\n",
    "            ground_truth_masks = load_all_masks_for_video(video)\n",
    "            f_measure, iou, f_label, iou_label = compute_all_metrics(masks[1:],ground_truth_masks[1:])\n",
    "            print(f_measure, iou, f_label, iou_label)\n",
    "                \n",
    "        if compute_video: \n",
    "            if verbose: print('Generating video')\n",
    "            if video['width'] % 2 != 0 or video['height'] % 2 != 0: \n",
    "                painted_images = pad_to_divisible_by_two(painted_images)\n",
    "            generate_video_from_frames(painted_images, output_path= folder_path + f\"/{video['id']}_{video_folder}.mp4\", fps = 10) \n",
    "\n",
    "        if save_masks:\n",
    "            if verbose: print('Saving masks') \n",
    "            path_to_masks = folder_path + '/masks'\n",
    "            if not os.path.exists(path_to_masks): os.makedirs(path_to_masks)\n",
    "            for i,mask in enumerate(painted_images): \n",
    "                image = Image.fromarray(mask)\n",
    "                image.save(os.path.join(path_to_masks, '{:05d}.png'.format(i + 1)))\n",
    "\n",
    "                \n",
    "    return masks, logits, painted_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing BaseSegmenter to cuda:0\n",
      "Hyperparameters read from the model weights: C^k=64, C^v=512, C^h=64\n",
      "Single object mode: False\n",
      "Sam Refinement NOT ACTIVATED\n",
      "Initializing BaseSegmenter to cuda:0\n",
      "Hyperparameters read from the model weights: C^k=64, C^v=512, C^h=64\n",
      "Single object mode: False\n",
      "Sam Refinement ACTIVATED. Mode: mask_bbox_pos_neg\n"
     ]
    }
   ],
   "source": [
    "SAM_checkpoint = \"./checkpoints/sam_vit_h_4b8939.pth\"\n",
    "SAM_hq_checkpoints = \"./checkpoints/sam_hq_vit_h.pth\"\n",
    "xmem_checkpoint = \"./checkpoints/XMem-s012.pth\"\n",
    "e2fgvi_checkpoint = \"./checkpoints/E2FGVI-HQ-CVPR22.pth\"\n",
    "args = {\n",
    "    'use_refinement' : False\n",
    "        }\n",
    "model = TrackingAnything(SAM_checkpoint, xmem_checkpoint, e2fgvi_checkpoint,args)\n",
    "\n",
    "''' \n",
    "args = {\n",
    "    'use_refinement' : True,\n",
    "    'refinement_mode' : 'bbox'\n",
    "         }\n",
    "modelSamBbox = TrackingAnything(SAM_checkpoint, xmem_checkpoint, e2fgvi_checkpoint,args)\n",
    "\n",
    "\n",
    "args = {\n",
    "   'use_refinement' : True,\n",
    "   'refinement_mode' : 'point'\n",
    "       }\n",
    "modelSamPoint = TrackingAnything(SAM_checkpoint, xmem_checkpoint, e2fgvi_checkpoint,args)\n",
    "\n",
    "\n",
    "\n",
    "args = {\n",
    "   'use_refinement' : True,\n",
    "   'refinement_mode' : 'both'\n",
    "       }\n",
    "modelBoth = TrackingAnything(SAM_checkpoint, xmem_checkpoint, e2fgvi_checkpoint,args)\n",
    "\n",
    "'''\n",
    "args = {\n",
    "   'use_refinement' : True,\n",
    "   'refinement_mode' : 'mask_bbox_pos_neg'\n",
    "       }\n",
    "modelBothNeg = TrackingAnything(SAM_checkpoint, xmem_checkpoint, e2fgvi_checkpoint,args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vidToTest = select_smaller_set(vidTrain,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tracking image: 100%|██████████| 21/21 [00:00<00:00, 24.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18012959829450154 0.11718963 {1: 0.16035959304449188, 2: 0.06073457267986593, 3: 0.1851564090402146, 4: 0.12183350504265537, 5: 0.0668668643459481, 6: 0.0403632372004753, 7: 0.0, 8: 0.0, 9: 0.0, 10: 0.0} {1: 0.11090765322937288, 2: 0.03560684171917701, 3: 0.13267274252721278, 4: 0.08055986689446075, 5: 0.053229007279399644, 6: 0.024224088284481037, 7: 0.0, 8: 0.0, 9: 0.0, 10: 0.0}\n"
     ]
    }
   ],
   "source": [
    "masks, logits, painted_images = run_model_on_ovis_set(name = 'FirstName',model = model, path_set = ovis_images,videos = vidToTest[8:9],annotations = annTrain,compute_metrics = True, save_masks=False, compute_video=True,verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tracking image: 100%|██████████| 18/18 [00:06<00:00,  2.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.661423838068007 0.58558905 {1: 0.6622708741412114, 2: 0.52261799744606} {1: 0.6229903321812119, 2: 0.450181631876849}\n"
     ]
    }
   ],
   "source": [
    "masks, logits, painted_images = run_model_on_ovis_set(name = 'CCCC',model = modelBothNeg, path_set = ovis_images,videos = vidToTest[0:1],annotations = annTrain,compute_metrics = True, save_masks=True, compute_video=True,verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(317, 640, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "painted_images[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(318, 640, 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_to_divisible_by_two(painted_images)[0].shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JUNK TESTING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = load_images_from_folder(ovis_images,vidTrain[1]['file_names'])\n",
    "plt.imshow(images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for video in vidTrain: \n",
    "    if video['width'] % 2 != 0 or video['height'] % 2 != 0:\n",
    "        count+= 1\n",
    "        print(video['width'], video['height'])\n",
    "count"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venvTA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
